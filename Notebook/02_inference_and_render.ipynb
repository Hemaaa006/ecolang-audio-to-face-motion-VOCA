{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zW6TnoYQ6TFK",
        "outputId": "94ece319-5da0-48ab-c787-edfd533c7485"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8OEAXxT3iyn",
        "outputId": "02f235ed-c240-4ea2-a462-d7709d1d0bc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.0/737.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for PyOpenGL (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package libegl1-mesa:amd64.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../libegl1-mesa_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libegl1-mesa:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up libegl1-mesa:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip -q install smplx trimesh pyrender imageio imageio-ffmpeg pyglet\n",
        "!apt-get -qq update\n",
        "!apt-get -qq install -y ffmpeg libgl1-mesa-glx libegl1-mesa\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SMPLX_MODEL_DIR = \"/content/drive/MyDrive/OSXBackup/OSX/common/utils/human_model_files\"\n"
      ],
      "metadata": {
        "id": "5C2O8kcp3m7s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "SMPLX_MODEL_DIR = \"/content/drive/MyDrive/OSXBackup/human_models_folder\"\n",
        "\n",
        "layer = smplx.create(\n",
        "    SMPLX_MODEL_DIR,\n",
        "    model_type=\"smplx\",\n",
        "    gender=\"neutral\",\n",
        "    use_pca=False,\n",
        "    batch_size=1,\n",
        "    create_global_orient=True,\n",
        "    create_body_pose=True,\n",
        "    create_betas=True,\n",
        "    create_expression=True,\n",
        "    create_jaw_pose=True,\n",
        "    create_left_hand_pose=True,\n",
        "    create_right_hand_pose=True,\n",
        ").to(device).eval()\n",
        "\n",
        "faces = layer.faces\n",
        "print(\"Loaded SMPL-X. faces:\", faces.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReFC8X9X3m5j",
        "outputId": "755cc699-28a4-41e3-e0af-2810d2544263"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n",
            "Loaded SMPL-X. faces: (20908, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import smplx\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "# --- load predicted motion ---\n",
        "MOTION_NPZ = \"/content/motion_20s_pred.npz\"\n",
        "z = np.load(MOTION_NPZ, allow_pickle=True)\n",
        "\n",
        "poses = z[\"poses\"].astype(np.float32)          # (T,55,3)\n",
        "expr  = z[\"expressions\"].astype(np.float32)    # (T,10)\n",
        "betas = z[\"betas\"].astype(np.float32)          # (10,)\n",
        "fps   = int(z[\"fps\"])\n",
        "transl = z[\"transl\"].astype(np.float32)        # (T,3)\n",
        "\n",
        "# --- choose how many seconds to render ---\n",
        "RENDER_SECONDS = 10\n",
        "T = min(poses.shape[0], int(RENDER_SECONDS * fps))\n",
        "print(\"Rendering frames:\", T)\n",
        "\n",
        "# --- recreate SMPL-X with batch_size=T ---\n",
        "SMPLX_MODEL_DIR = \"/content/drive/MyDrive/OSXBackup/OSX/common/utils/human_model_files\"\n",
        "layer = smplx.create(\n",
        "    model_path=SMPLX_MODEL_DIR,\n",
        "    model_type=\"smplx\",\n",
        "    gender=\"neutral\",\n",
        "    use_pca=False,\n",
        "    batch_size=T,                     # <-- critical\n",
        "    create_global_orient=True,\n",
        "    create_body_pose=True,\n",
        "    create_betas=True,\n",
        "    create_expression=True,\n",
        "    create_jaw_pose=True,\n",
        "    create_leye_pose=True,\n",
        "    create_reye_pose=True,\n",
        "    create_left_hand_pose=True,\n",
        "    create_right_hand_pose=True,\n",
        ").to(device).eval()\n",
        "\n",
        "faces = layer.faces\n",
        "\n",
        "# --- split packed poses (SMPL-X 55 joints) ---\n",
        "global_orient = poses[:T, 0, :]                         # (T,3)\n",
        "body_pose     = poses[:T, 1:22, :].reshape(T, -1)       # (T,63)\n",
        "jaw_pose      = poses[:T, 22, :]                        # (T,3)\n",
        "leye_pose     = poses[:T, 23, :]                        # (T,3)\n",
        "reye_pose     = poses[:T, 24, :]                        # (T,3)\n",
        "\n",
        "left_hand     = poses[:T, 25:40, :].reshape(T, -1)      # (T,45)\n",
        "right_hand    = poses[:T, 40:55, :].reshape(T, -1)      # (T,45)\n",
        "\n",
        "betas_T = np.repeat(betas.reshape(1, 10), T, axis=0)    # (T,10)\n",
        "transl_T = transl[:T]                                   # (T,3)\n",
        "\n",
        "# --- to torch ---\n",
        "global_orient_t = torch.from_numpy(global_orient).float().to(device)\n",
        "body_pose_t     = torch.from_numpy(body_pose).float().to(device)\n",
        "jaw_pose_t      = torch.from_numpy(jaw_pose).float().to(device)\n",
        "leye_pose_t     = torch.from_numpy(leye_pose).float().to(device)\n",
        "reye_pose_t     = torch.from_numpy(reye_pose).float().to(device)\n",
        "\n",
        "expr_t          = torch.from_numpy(expr[:T]).float().to(device)\n",
        "left_hand_t     = torch.from_numpy(left_hand).float().to(device)\n",
        "right_hand_t    = torch.from_numpy(right_hand).float().to(device)\n",
        "\n",
        "betas_t         = torch.from_numpy(betas_T).float().to(device)\n",
        "transl_t        = torch.from_numpy(transl_T).float().to(device)\n",
        "\n",
        "print(\"Shapes into SMPL-X:\",\n",
        "      global_orient_t.shape, body_pose_t.shape, jaw_pose_t.shape,\n",
        "      leye_pose_t.shape, reye_pose_t.shape,\n",
        "      left_hand_t.shape, right_hand_t.shape,\n",
        "      expr_t.shape, betas_t.shape, transl_t.shape)\n",
        "\n",
        "# --- forward ---\n",
        "with torch.no_grad():\n",
        "    out = layer(\n",
        "        betas=betas_t,\n",
        "        global_orient=global_orient_t,\n",
        "        body_pose=body_pose_t,\n",
        "        jaw_pose=jaw_pose_t,\n",
        "        leye_pose=leye_pose_t,\n",
        "        reye_pose=reye_pose_t,\n",
        "        left_hand_pose=left_hand_t,\n",
        "        right_hand_pose=right_hand_t,\n",
        "        expression=expr_t,\n",
        "        transl=transl_t,\n",
        "        return_verts=True\n",
        "    )\n",
        "\n",
        "verts = out.vertices.detach().cpu().numpy()  # (T,V,3)\n",
        "print(\"verts:\", verts.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQX_AuIc3m3Q",
        "outputId": "204dd82f-72dd-459c-d5e6-dfea493b1312"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n",
            "Rendering frames: 300\n",
            "Shapes into SMPL-X: torch.Size([300, 3]) torch.Size([300, 63]) torch.Size([300, 3]) torch.Size([300, 3]) torch.Size([300, 3]) torch.Size([300, 45]) torch.Size([300, 45]) torch.Size([300, 10]) torch.Size([300, 10]) torch.Size([300, 3])\n",
            "verts: (300, 10475, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q8E6d6mG3myx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq update\n",
        "!apt-get -qq install -y libegl1-mesa libgl1-mesa-glx mesa-utils xvfb ffmpeg\n",
        "!pip -q install pyrender imageio imageio-ffmpeg trimesh pyglet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hvUY8bG8wTI",
        "outputId": "1a4b8b87-f126-40e9-cc2c-a655ade16438"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package mesa-utils-bin:amd64.\n",
            "(Reading database ... 117534 files and directories currently installed.)\n",
            "Preparing to unpack .../mesa-utils-bin_8.4.0-1ubuntu1_amd64.deb ...\n",
            "Unpacking mesa-utils-bin:amd64 (8.4.0-1ubuntu1) ...\n",
            "Selecting previously unselected package mesa-utils.\n",
            "Preparing to unpack .../mesa-utils_8.4.0-1ubuntu1_amd64.deb ...\n",
            "Unpacking mesa-utils (8.4.0-1ubuntu1) ...\n",
            "Setting up mesa-utils-bin:amd64 (8.4.0-1ubuntu1) ...\n",
            "Setting up mesa-utils (8.4.0-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n"
      ],
      "metadata": {
        "id": "l13cjgp88wQY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import trimesh\n",
        "import pyrender\n",
        "import imageio\n",
        "\n",
        "def render_video_egl(verts, faces, fps, out_mp4=\"face_motion.mp4\", img_size=(640, 640)):\n",
        "    scene = pyrender.Scene(bg_color=[255, 255, 255, 255], ambient_light=[0.3, 0.3, 0.3])\n",
        "\n",
        "    # Create mesh\n",
        "    mesh_tr = trimesh.Trimesh(vertices=verts[0], faces=faces, process=False)\n",
        "    mesh = pyrender.Mesh.from_trimesh(mesh_tr, smooth=True)\n",
        "    mesh_node = scene.add(mesh)\n",
        "\n",
        "    # Camera: closer + slightly up for more face focus\n",
        "    camera = pyrender.PerspectiveCamera(yfov=np.pi / 3.0)\n",
        "    cam_pose = np.eye(4)\n",
        "    cam_pose[2, 3] = 1.6   # zoom in (smaller = closer)\n",
        "    cam_pose[1, 3] = 0.15  # slightly up\n",
        "    scene.add(camera, pose=cam_pose)\n",
        "\n",
        "    # Light\n",
        "    light = pyrender.DirectionalLight(color=np.ones(3), intensity=3.0)\n",
        "    scene.add(light, pose=cam_pose)\n",
        "\n",
        "    r = pyrender.OffscreenRenderer(viewport_width=img_size[0], viewport_height=img_size[1])\n",
        "\n",
        "    writer = imageio.get_writer(out_mp4, fps=fps, codec=\"libx264\", quality=8)\n",
        "\n",
        "    for i in range(verts.shape[0]):\n",
        "        # replace mesh\n",
        "        scene.remove_node(mesh_node)\n",
        "        mesh_tr = trimesh.Trimesh(vertices=verts[i], faces=faces, process=False)\n",
        "        mesh = pyrender.Mesh.from_trimesh(mesh_tr, smooth=True)\n",
        "        mesh_node = scene.add(mesh)\n",
        "\n",
        "        color, _ = r.render(scene)\n",
        "        writer.append_data(color)\n",
        "\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f\"Rendered {i+1}/{verts.shape[0]} frames\")\n",
        "\n",
        "    writer.close()\n",
        "    r.delete()\n",
        "    return out_mp4\n",
        "\n",
        "out_mp4 = render_video_egl(verts, faces, fps=fps, out_mp4=\"face_motion.mp4\", img_size=(640,640))\n",
        "out_mp4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "bW5CFv_C8wN-",
        "outputId": "ec388365-e12a-46d7-c710-3c3549cea85c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rendered 50/300 frames\n",
            "Rendered 100/300 frames\n",
            "Rendered 150/300 frames\n",
            "Rendered 200/300 frames\n",
            "Rendered 250/300 frames\n",
            "Rendered 300/300 frames\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'face_motion.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8RsJKflb-BOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Audio"
      ],
      "metadata": {
        "id": "huEZSZk5-ByQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FULL_AUDIO = \"/content/drive/MyDrive/Extracted_Parameters/ch08_speakerview_16k.wav\"  # CHANGE THIS\n",
        "START_SEC = 300    # e.g. start at 5 minutes\n",
        "DURATION = 20      # seconds\n"
      ],
      "metadata": {
        "id": "U1YCd9wd-D0R"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_SLICE = \"audio_20s.wav\"\n",
        "\n",
        "!ffmpeg -y \\\n",
        "  -ss {START_SEC} \\\n",
        "  -t {DURATION} \\\n",
        "  -i \"{FULL_AUDIO}\" \\\n",
        "  -ac 1 -ar 16000 \\\n",
        "  \"{AUDIO_SLICE}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2FP13Gd-DyY",
        "outputId": "f2abb64b-348c-45b1-8502-05a3d4c40fc6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from '/content/drive/MyDrive/Extracted_Parameters/ch08_speakerview_16k.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf61.7.100\n",
            "  Duration: 00:43:06.52, bitrate: 256 kb/s\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (pcm_s16le (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'audio_20s.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=     625kB time=00:00:19.96 bitrate= 256.4kbits/s speed= 129x    \n",
            "video:0kB audio:625kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.012187%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -y \\\n",
        "  -i face_motion.mp4 \\\n",
        "  -i audio_20s.wav \\\n",
        "  -c:v copy \\\n",
        "  -c:a aac \\\n",
        "  -shortest \\\n",
        "  face_motion_with_audio.mp4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY_QGtpG-Dvh",
        "outputId": "4cfd1a03-4c10-4f98-94e6-6a685ba9a080"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'face_motion.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf61.1.100\n",
            "  Duration: 00:00:10.00, start: 0.000000, bitrate: 62 kb/s\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x640, 58 kb/s, 30 fps, 30 tbr, 15360 tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc61.3.100 libx264\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : mono\n",
            "\u001b[0mInput #1, wav, from 'audio_20s.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.76.100\n",
            "  Duration: 00:00:20.00, bitrate: 256 kb/s\n",
            "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, mp4, to 'face_motion_with_audio.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.76.100\n",
            "  Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 640x640, q=2-31, 58 kb/s, 30 fps, 30 tbr, 15360 tbn, 15360 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc61.3.100 libx264\n",
            "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 16000 Hz, mono, fltp, 69 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 aac\n",
            "frame=    0 fps=0.0 q=-1.0 size=       0kB time=00:00:00.00 bitrate=N/A speed=   0x    \rframe=  300 fps=0.0 q=-1.0 Lsize=     164kB time=00:00:09.92 bitrate= 135.1kbits/s speed= 136x    \n",
            "video:72kB audio:85kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 4.501638%\n",
            "\u001b[1;36m[aac @ 0x5c846a953400] \u001b[0mQavg: 137.831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iWblb3oM_zll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EuTY1l-0_ziu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJR_e1BQ3mtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uto8xW91-Ajd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VLmGzGlW-Ago"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yo_Rq2vi-Ad_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SEVJB0rT-AbX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}